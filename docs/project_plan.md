# 프로젝트 로드맵 – CSV Viewer & Visualizer

## 1. 목표 및 요구사항
- 대용량 CSV(`train.csv` 2.6GB 등)를 효율적으로 탐색하고, 웹 UI에서 엑셀 유사 테이블 및 그래프를 제공한다.
- 데이터 로딩, 필터링, 집계가 지연 없이 수행되도록 스트리밍/쿼리 기반 아키텍처를 채택한다.
- 사용자 친화적인 인터페이스(파일 선택, 검색, 시각화)를 제공하고 향후 배포(로컬/사내)까지 고려한다.

## 2. 전체 아키텍처 개요
- **데이터 계층**: DuckDB(우선) 또는 Polars를 활용해 CSV를 on-demand로 읽고, 필요 시 Parquet 캐시 생성.
- **API 계층**: FastAPI 기반 REST + 필요 시 WebSocket(프로그레스, 실시간 업데이트).
- **프론트엔드**: React + Ag-Grid(테이블) + Plotly.js/ECharts(그래프) 조합, Vite 빌드.
- **시각화 전략**: 서버에서 사전 집계/샘플링 → 클라이언트는 경량 데이터만 렌더링.
- **배포**: Docker 기반 로컬 실행, 또는 사내 서버 배포 옵션 확보.

## 3. 단계별 실행 계획

### 3.1 초반 세팅 (주 1)
1. **리포지토리 구조화**
   - `backend/`, `frontend/`, `scripts/`, `docs/` 디렉터리 구성.
   - 공통 `.env` 템플릿 및 config 예시 작성.
2. **기본 의존성 설치**
   - Backend: Python 3.11+, FastAPI, DuckDB, Polars, SQLAlchemy(Optional).
   - Frontend: Node 20+, React 18, Vite, Ag-Grid, Plotly.js(or ECharts), Tailwind/Chakra 등 UI 프레임워크.
3. **CSV 샘플 로딩 검증**
   - DuckDB로 `train.csv` 일부 로딩, 컬럼 타입 추론, 기본 통계 수집 스크립트 작성.
   - 메모리 사용량/쿼리 시간 파악 후 로깅.

### 3.2 데이터 계층 안정화 (주 2)
1. **데이터 접근 모듈**
   - DuckDB 커넥션 풀, 쿼리 래퍼 제작.
   - 공통 유틸: 컬럼 정보 조회, 행 카운트, 샘플링 함수.
2. **Parquet 캐시 파이프라인**
   - `scripts/convert_to_parquet.py`: CSV → Parquet 변환(멀티스레드, 청크 단위).
   - 변환 진행률을 로그/메트릭으로 노출.
3. **테스트**
   - Pytest 기반 단위 테스트(샘플 CSV로 기능 검증).
   - GitHub Actions or CI 스크립트 초안.

### 3.3 백엔드 API 구현 (주 3~4)
1. **FastAPI 기본 구조**
   - 라우트: `/files`, `/tables`, `/preview`, `/query`, `/summary`, `/charts`.
   - CORS 설정 및 에러 핸들링.
2. **테이블 미리보기/페이징**
   - 페이지 번호, 페이지 크기, 정렬/필터 옵션 처리.
   - DuckDB 쿼리 → Arrow/JSON 직렬화.
3. **요약 & 분석 API**
   - 컬럼별 통계(최소/최대/평균/Null 비율).
   - 그룹바이/히스토그램/시계열용 사전 집계 API.
4. **비동기 처리**
   - 긴 쿼리/변환 작업을 BackgroundTasks 또는 Celery/RQ로 분리하는 구조 초안.
5. **문서화**
   - OpenAPI 문서, 예시 요청/응답, 에러 코드 명세.

### 3.4 프론트엔드 UI/UX 구현 (주 4~6)
1. **프로젝트 셋업**
   - Vite + React 앱, 라우팅, 상태관리(Zustand/Recoil/Redux Toolkit 중 선택).
   - `.env` 기반 API 엔드포인트 설정.
2. **테이블 화면**
   - Ag-Grid(또는 TanStack Table)로 가상 스크롤·컬럼 리사이즈·필터 구현.
   - 상태 표시(로딩, 쿼리 진행률) 및 에러 토스트.
3. **그래프 대시보드**
   - Plotly.js/ECharts로 히스토그램, 시계열, 산점도 등 템플릿 구성.
   - 사용자 입력(컬럼 선택, 집계 타입) → API 호출 → 결과 렌더링까지 연결.
4. **파일/세션 관리**
   - 데이터 폴더 브라우징, 최근 파일 리스트.
   - 사용자 설정(페이지 크기, 테마) 저장 로직.
5. **UI 다듬기**
   - 반응형 레이아웃, 다크 테마, 접근성 고려.

### 3.5 성능 최적화 및 품질 확보 (주 7~8)
1. **성능 측정**
   - 백엔드: 주요 쿼리 벤치마크, 로깅/모니터링(uvicorn log + Prometheus exporter 고려).
   - 프론트엔드: Lighthouse 검사, 긴 리스트 렌더링 지연 체크.
2. **최적화**
   - DuckDB 쿼리 튜닝(인덱스, 캐시), Parquet 사전 변환 전략 결정.
   - 프론트엔드 메모이제이션, 스켈레톤 화면, 요청 배치.
3. **테스트 강화**
   - E2E 테스트(Playwright/Cypress)로 주요 시나리오 검증.
   - 회귀 테스트용 샘플 데이터셋 세트 구성.

### 3.6 배포 및 문서 (주 9)
1. **배포 옵션**
   - Docker Compose: backend + frontend + optional DuckDB/Parquet 볼륨.
   - 단일 실행 스크립트(`run_local.ps1` / `run_local.sh`) 제공.
2. **운영 문서**
   - 설치 가이드, 환경 변수 설명, 일반적인 문제 해결 FAQ.
   - 데이터 보안/권한 관리 유의사항(사내 배포 대비).
3. **추가 기능 로드맵**
   - 사용자 정의 쿼리 저장, 그래프 export, 공유 링크, 알림 등 장기 과제 리스트업.

## 4. 리스크 및 대응 전략
- **대용량 처리 병목**: DuckDB/Polars 스트리밍, Parquet 캐시, 청크 처리로 완화.
- **UI 반응성 저하**: 가상 스크롤, 요청 배치, 서버 집계로 데이터 전송 최소화.
- **데이터 타입 다양성**: 스키마 추론 결과 검증, 사용자 정의 타입 매핑 옵션 제공.
- **동시 사용자 증가**: 커넥션 풀, 캐시 계층, 향후 분산 확장 고려.

## 5. 다음 액션
1. DuckDB 기반 CSV 로딩 프로토타입 작성 및 성능 로그 공유.
2. FastAPI + React 기본 골격 생성, CI 파이프라인 초안 추가.
3. 우선 구현할 그래프/분석 요구사항 목록 확정(사용자 인터뷰 또는 니즈 정리).

문서 최신화 주기: 주요 마일스톤 종료 후 또는 요구사항 변경 시 업데이트.
